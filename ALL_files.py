# —É—á–∞—Å—Ç–æ–∫ –∫–æ–¥–∞ —Ñ–∞–π–ª–∞ main.py

import sys
import signal
import time
import logging
import os

from modules.utils.config_manager import ConfigManager
from modules.utils.logs import get_logger, log_system_info
from modules.utils.state_manager import StateManager
from modules.utils.media_handler import MediaHandler
from modules.rag_system.rag_retriever import RAGRetriever
from modules.external_apis.telegram_client import TelegramClient
from modules.external_apis.web_search import WebSearchClient
from modules.content_generation.lm_client import LMStudioClient
from modules.content_generation.prompt_builder import PromptBuilder
from modules.content_generation.content_validator import ContentValidator

class MonitoringService:
    def __init__(self, logger):
        self.topics_processed = 0
        self.topics_failed = 0
        self.logger = logger

    def log_success(self, topic):
        self.topics_processed += 1
        self.logger.info(f"[MONITOR] Topic processed: {topic}")

    def log_failure(self, topic, error):
        self.topics_failed += 1
        self.logger.error(f"[MONITOR] Topic failed: {topic}, error: {error}")

    def report(self):
        self.logger.info(f"[MONITOR] Stats: Success: {self.topics_processed}, Failed: {self.topics_failed}")

class RAGIngestionService:
    def __init__(self, rag_retriever, logger):
        self.rag_retriever = rag_retriever
        self.logger = logger

    def build_knowledge_base(self, folder):
        try:
            self.rag_retriever.process_inform_folder(folder)
            self.rag_retriever.build_knowledge_base()
            self.logger.info("Initial RAG knowledge base built.")
        except Exception as e:
            self.logger.error("Knowledge base build failed", exc_info=True)
            raise

class TelegramRAGSystem:
    TELEGRAM_TEXT_LIMIT = 4096
    TELEGRAM_CAPTION_LIMIT = 1024

    def __init__(self, config_path: str = "config/config.json"):
        self.logger = get_logger("Main")
        self.logger.info("üöÄ Initializing TelegramRAGSystem...")
        self.shutdown_requested = False

        try:
            self.config_manager = ConfigManager(config_path)
            self.config = self.config_manager.config
        except Exception as e:
            self.logger.critical("Config initialization failed", exc_info=True)
            sys.exit(1)

        self.setup_logging()
        self.validate_configuration()
        self.initialize_services()
        self.autoload_topics()

    def setup_logging(self):
        log_system_info(self.logger)

    def validate_configuration(self):
        if not self.config_manager.validate_config():
            self.logger.critical("Configuration validation failed.")
            sys.exit(1)
        self.logger.info("Configuration validated successfully.")

    def initialize_services(self):
        try:
            self.rag_retriever = RAGRetriever(config=self.config["rag"])
            self.state_manager = StateManager(state_file="data/state.json")
            self.monitoring = MonitoringService(self.logger)
            self.ingestion = RAGIngestionService(self.rag_retriever, self.logger)

            self.lm_client = LMStudioClient(
                base_url=self.config["lm_studio"]["base_url"],
                model=self.config["lm_studio"]["model"],
                config=self.config["lm_studio"]
            )
            self.prompt_builder = PromptBuilder(
                prompt_folders=self.config["paths"].get("prompt_folders", [
                    "data/prompt_1", "data/prompt_2", "data/prompt_3"
                ])
            )
            self.content_validator = ContentValidator(config=self.config)

            serper_api_key = self.config_manager.get_serper_api_key()
            serper_endpoint = self.config_manager.get_config_value("serper.endpoint", "https://google.serper.dev/search")
            serper_results_limit = self.config_manager.get_config_value("serper.results_limit", 10)
            self.web_search = WebSearchClient(
                api_key=serper_api_key,
                endpoint=serper_endpoint,
                results_limit=serper_results_limit
            )
            self.media_handler = MediaHandler(
                media_folder=self.config["paths"].get("media_dir", "media"),
                config=self.config
            )

            token = self.config_manager.get_telegram_token()
            channel_id = self.config_manager.get_telegram_channel_id()
            self.telegram_client = TelegramClient(
                token=token,
                channel_id=channel_id,
                config=self.config["telegram"]
            )

        except Exception as e:
            self.logger.critical("Component initialization failed", exc_info=True)
            sys.exit(1)

    def autoload_topics(self):
        topics_file = "data/topics.txt"
        if not os.path.isfile(topics_file):
            self.logger.warning(f"Topics file not found: {topics_file}")
            return

        try:
            with open(topics_file, "r", encoding="utf-8") as f:
                topics = [line.strip() for line in f if line.strip()]
            existing = set(self.state_manager.get_unprocessed_topics() +
                           self.state_manager.get_processed_topics() +
                           self.state_manager.get_failed_topics())
            new_topics = [t for t in topics if t not in existing]
            if new_topics:
                self.logger.info(f"Autoloading {len(new_topics)} new topics into queue")
                self.state_manager.add_topics(new_topics)
            else:
                self.logger.info("No new topics found to autoload")
        except Exception as e:
            self.logger.error("Failed to autoload topics", exc_info=True)

    def graceful_shutdown(self, *_):
        self.shutdown_requested = True
        self.logger.warning("Shutdown signal received. Exiting loop...")

    def get_next_topic(self) -> str:
        topic = self.state_manager.get_next_unprocessed_topic()
        if topic:
            self.logger.info(f"Next topic selected: {topic}")
        else:
            self.logger.info("No more topics to process.")
        return topic

    def combine_contexts(self, rag_context: str, web_context: str) -> str:
        if not rag_context and not web_context:
            return ""
        elif not rag_context:
            return f"[Web context only]\n\n{web_context}"
        elif not web_context:
            return f"{rag_context}\n\n[–ù–µ—Ç web-–∫–æ–Ω—Ç–µ–∫—Å—Ç–∞]"
        return f"{rag_context}\n\n[–î–æ–ø. –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –ø–æ–∏—Å–∫–∞]\n\n{web_context}"

    def update_processing_state(self, topic: str, success: bool):
        try:
            self.state_manager.mark_topic_processed(topic, success)
            self.logger.info(f"Topic '{topic}' marked as {'processed' if success else 'failed'}.")
        except Exception as e:
            self.logger.error(f"Failed to update state for topic '{topic}': {str(e)}", exc_info=True)

    def handle_error(self, topic: str, error: Exception):
        try:
            self.logger.error(f"Error processing topic '{topic}': {str(error)}", exc_info=True)
            self.update_processing_state(topic, success=False)
            self.monitoring.log_failure(topic, error)
        except Exception as e:
            self.logger.critical("Failed during error handling!", exc_info=True)

    def main_processing_loop(self):
        while not self.shutdown_requested:
            topic = self.get_next_topic()
            if not topic:
                break

            try:
                # 1. –ü–æ–∏—Å–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –≤ RAG
                rag_context = self.rag_retriever.retrieve_context(topic)
                if rag_context is None:
                    self.logger.warning(f"RAG context retrieval returned None for topic: {topic}")
                    raise ValueError("RAG context retrieval returned None")
                if not isinstance(rag_context, str) or not rag_context.strip():
                    self.logger.warning(f"RAG context is empty for topic: {topic}")

                # 2. Web-–ø–æ–∏—Å–∫ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
                web_results = self.web_search.search(topic)
                if web_results is None:
                    self.logger.warning(f"Web search returned None for topic: {topic}")
                    raise ValueError("Web search returned None")
                web_context = self.web_search.extract_content(web_results)
                if not isinstance(web_context, str) or not web_context.strip():
                    self.logger.warning(f"Web context is empty for topic: {topic}")

                # 3. –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤
                full_context = self.combine_contexts(rag_context, web_context)
                self.logger.debug(f"[{topic}] full_context length: {len(full_context)}, preview: {full_context[:300]}")

                # 4. –í—ã–±–æ—Ä –º–µ–¥–∏–∞—Ñ–∞–π–ª–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
                media_file = None
                try:
                    media_file = self.media_handler.get_random_media_file()
                    if media_file and not self.media_handler.validate_media_file(media_file):
                        self.logger.warning(f"Media file {media_file} is not valid. Skipping media.")
                        media_file = None
                except Exception as e:
                    self.logger.warning(f"Media handler error: {str(e)}")

                # 5. –°–±–æ—Ä–∫–∞ –ø—Ä–æ–º–ø—Ç–∞ —Å —Ä–∞—Å–ø–∞–∫–æ–≤–∫–æ–π –∫–æ—Ä—Ç–µ–∂–∞ (prompt, has_uploadfile, prompt_template)
                # PromptBuilder –¥–æ–ª–∂–µ–Ω –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å prompt, has_uploadfile, prompt_template
                prompt, has_uploadfile, prompt_template = self.prompt_builder.build_prompt(
                    topic=topic,
                    context=full_context,
                    media_file=media_file
                )

                # 6. –û–±—Ä–µ–∑–∫–∞ context –¥–ª—è Telegram (–æ—Ç–¥–µ–ª—å–Ω–æ –¥–ª—è Telegram, –Ω–µ –¥–ª—è LM Studio!)
                max_context_length = self.TELEGRAM_CAPTION_LIMIT if has_uploadfile else self.TELEGRAM_TEXT_LIMIT
                if len(full_context) > max_context_length:
                    self.logger.warning(
                        f"Context too long ({len(full_context)} > {max_context_length}) for topic: {topic}. Truncating."
                    )
                    full_context = full_context[:max_context_length]

                if not prompt or not prompt.strip():
                    self.logger.error(f"Prompt building failed (empty) for topic '{topic}'.")
                    self.update_processing_state(topic, success=False)
                    self.monitoring.log_failure(topic, "Prompt building failed (empty prompt)")
                    continue

                self.logger.debug(f"Prompt to LM Studio for topic '{topic}':\n{prompt[:1000]}")

                # 7. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞ LM Studio (—Ç–µ–ø–µ—Ä—å –ø–µ—Ä–µ–¥–∞–µ–º prompt_template, topic, context, media_file)
                max_lm_retries = self.config["lm_studio"].get("max_retries", 3)
                try:
                    content = self.lm_client.generate_with_retry(
                        prompt_template,
                        topic,
                        full_context,
                        media_file,
                        max_retries=max_lm_retries,
                        with_media=has_uploadfile
                    )
                except Exception as e:
                    self.logger.error(f"LM Studio generation failed after retries for topic '{topic}': {e}")
                    self.logger.error(f"Prompt (truncated): {prompt[:1000]}")
                    self.update_processing_state(topic, success=False)
                    self.monitoring.log_failure(topic, f"LM Studio generation failed: {e}")
                    continue

                self.logger.debug(f"LM Studio response for topic '{topic}': {content[:1000]}")
                if not content or not content.strip():
                    self.logger.error(f"Generated content is empty for topic '{topic}'.")
                    self.update_processing_state(topic, success=False)
                    self.monitoring.log_failure(topic, "Generated content is empty")
                    continue

                # 8. –í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫ Telegram
                try:
                    validated_content = self.content_validator.validate_content(
                        content,
                        has_media=has_uploadfile
                    )
                except Exception as e:
                    self.logger.error(f"Content validation failed for topic '{topic}': {e}")
                    self.logger.error(f"Raw content: {content[:1000]}")
                    self.update_processing_state(topic, success=False)
                    self.monitoring.log_failure(topic, f"Content validation failed: {e}")
                    continue

                if not validated_content or not validated_content.strip():
                    self.logger.error(f"Validated content is empty for topic '{topic}'.")
                    self.update_processing_state(topic, success=False)
                    self.monitoring.log_failure(topic, "Validated content is empty")
                    continue

                # 9. –ü—É–±–ª–∏–∫–∞—Ü–∏—è –≤ Telegram
                success = False
                max_retries = self.config["telegram"].get("max_retries", 3)
                for attempt in range(1, max_retries + 1):
                    try:
                        if has_uploadfile and media_file:
                            success = self.telegram_client.send_media_message(validated_content, media_file)
                        else:
                            success = self.telegram_client.send_text_message(validated_content)
                        if success:
                            break
                    except Exception as te:
                        self.logger.error(f"Telegram send failed (attempt {attempt}): {te}")
                        time.sleep(2)
                self.update_processing_state(topic, success)
                if success:
                    self.monitoring.log_success(topic)
                else:
                    self.monitoring.log_failure(topic, "Telegram send failed")

                self.monitoring.report()
                time.sleep(self.config["telegram"].get("post_interval", 15))

            except Exception as e:
                self.handle_error(topic, e)
                continue

    def run(self):
        self.logger.info("System starting up...")
        signal.signal(signal.SIGINT, self.graceful_shutdown)
        signal.signal(signal.SIGTERM, self.graceful_shutdown)
        try:
            self.ingestion.build_knowledge_base(self.config["rag"].get("inform_folder", "inform/"))
        except Exception as e:
            self.logger.critical(f"Failed to build RAG knowledge base: {e}", exc_info=True)
            sys.exit(1)
        self.main_processing_loop()
        self.logger.info("System shut down gracefully.")

if __name__ == "__main__":
    system = TelegramRAGSystem()
    system.run()



# —É—á–∞—Å—Ç–æ–∫ –∫–æ–¥–∞ —Ñ–∞–π–ª–∞ content_validator.py

import logging
import re

class ContentValidator:
    """
    –í–∞–ª–∏–¥–∞—Ç–æ—Ä –∏ –∫–æ—Ä—Ä–µ–∫—Ç–æ—Ä —Ç–µ–∫—Å—Ç–∞ –¥–ª—è Telegram-–ø–æ—Å—Ç–∏–Ω–≥–∞.
    - –ö–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ—Ç –ª–∏–º–∏—Ç—ã Telegram (4096/1024)
    - –£–¥–∞–ª—è–µ—Ç —Ç–∞–±–ª–∏—Ü—ã (markdown/html), —Ä–∞–∑–º—ã—à–ª–µ–Ω–∏—è (<think>...</think>), —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã
    - –≠–∫—Ä–∞–Ω–∏—Ä—É–µ—Ç markdown V2, –∑–∞—â–∏—â–∞–µ—Ç –æ—Ç Telegram-–±–∞–Ω–æ–≤
    - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–º—ã—Å–ª–æ–≤—É—é –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—É—é –ø—Ä–∏–≥–æ–¥–Ω–æ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
    """

    TELEGRAM_TEXT_LIMIT = 4096
    TELEGRAM_CAPTION_LIMIT = 1024
    FORBIDDEN_SYMBOLS = ["\u202e", "\u202d", "\u202c"]  # RLO/LRO, –æ–ø–∞—Å–Ω—ã–µ –¥–ª—è Telegram
    MARKDOWN_SPECIAL = r'_*[]()~`>#+-=|{}.!'
    # –î–ª—è —É–¥–∞–ª–µ–Ω–∏—è —Ç–∞–±–ª–∏—Ü
    MARKDOWN_TABLE_PATTERN = re.compile(
        r'(?:\|[^\n|]+\|[^\n]*\n)+(?:\|[-:| ]+\|[^\n]*\n)+(?:\|[^\n|]+\|[^\n]*\n?)+', re.MULTILINE)
    HTML_TABLE_PATTERN = re.compile(r'<table[\s\S]*?</table>', re.IGNORECASE)
    # –î–ª—è —É–¥–∞–ª–µ–Ω–∏—è <think>...</think> –∏ –≤–∞—Ä–∏–∞—Ü–∏–π
    THINK_PATTERN = re.compile(r'<\s*think[^>]*>.*?<\s*/\s*think\s*>', re.IGNORECASE | re.DOTALL)

    def __init__(self, config=None):
        self.logger = logging.getLogger("ContentValidator")
        self.config = config or {}

    def validate_content(self, text: str, has_media: bool = False) -> str:
        """
        –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è: –ø–æ–ª–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ –ø–µ—Ä–µ–¥ Telegram.
        –ï—Å–ª–∏ –Ω–µ –ø—Ä–æ—Ö–æ–¥–∏—Ç –ª–∏–º–∏—Ç ‚Äî –≤–µ—Ä–Ω—É—Ç—å –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É, –≤—ã—à–µ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –ø–æ–≤—Ç–æ—Ä–Ω—ã–π –∑–∞–ø—Ä–æ—Å –∫ LLM.
        """
        if not isinstance(text, str):
            self.logger.error("Content for validation is not a string!")
            return ""

        text = text.strip()
        if not text:
            self.logger.warning("Empty content on validation entrance.")
            return ""

        text = self._basic_cleanup(text)
        text = self.remove_thinking_blocks(text)
        text = self.remove_tables(text)
        text = self.clean_html_markdown(text)
        text = self._remove_forbidden_symbols(text)
        text = self._deduplicate_empty_lines(text)
        text = self._fix_markdown(text)

        # –õ–∏–º–∏—Ç Telegram
        limit = self.TELEGRAM_CAPTION_LIMIT if has_media else self.TELEGRAM_TEXT_LIMIT
        if len(text) > limit:
            self.logger.warning(f"Content too long for Telegram ({len(text)} > {limit}), request shorter version in LLM.")
            return ""  # –ù—É–∂–Ω–æ –ø–æ–≤—Ç–æ—Ä–Ω–æ –∑–∞–ø—Ä–æ—Å–∏—Ç—å —É LLM ‚Äî –Ω–µ —Ä–µ–∑–∞—Ç—å –∑–¥–µ—Å—å!

        text = self._final_antiartifacts(text)
        text = text.strip()

        if not self.validate_content_quality(text):
            self.logger.warning("Content failed quality check: too short, nonsensical, or spammy.")
            return ""

        return text

    def _basic_cleanup(self, text: str) -> str:
        # –£–¥–∞–ª—è–µ–º –º—É—Å–æ—Ä: nan, None, NULL, –Ω–µ–≤–∏–¥–∏–º—ã–µ —Å–∏–º–≤–æ–ª—ã, —Å–ø–µ—Ü–∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã
        text = re.sub(r'\b(nan|None|null|NULL)\b', '', text, flags=re.I)
        text = re.sub(r'[\u200b-\u200f\u202a-\u202e]+', '', text)
        text = re.sub(r'\\x[0-9a-fA-F]{2}', '', text)
        text = re.sub(r'_x[0-9A-Fa-f]{4}_', '', text)
        text = re.sub(r'&[a-zA-Z0-9#]+;', '', text)
        text = re.sub(r' {3,}', '  ', text)
        return text

    def _remove_forbidden_symbols(self, text: str) -> str:
        for sym in self.FORBIDDEN_SYMBOLS:
            text = text.replace(sym, '')
        # –ú–æ–∂–Ω–æ —Ä–∞—Å—à–∏—Ä–∏—Ç—å —Å–ø–∏—Å–æ–∫ –∑–∞–ø—Ä–µ—â—ë–Ω–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤/emoji –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
        return text

    def _deduplicate_empty_lines(self, text: str) -> str:
        text = re.sub(r'\n\s*\n+', '\n\n', text)
        return text.strip('\n')

    def _fix_markdown(self, text: str) -> str:
        """
        –≠–∫—Ä–∞–Ω–∏—Ä—É–µ—Ç —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã markdown V2 –≤–Ω–µ –∫–æ–¥–∞/—Å—Å—ã–ª–æ–∫, –Ω–µ —Ç—Ä–æ–≥–∞–µ—Ç code blocks.
        """
        def escape_md(match):
            part = match.group(0)
            for c in self.MARKDOWN_SPECIAL:
                part = part.replace(c, '\\' + c)
            return part

        # –ù–µ —ç–∫—Ä–∞–Ω–∏—Ä—É–µ–º –≤ inline code –∏ code blocks
        segments = []
        last_end = 0
        for m in re.finditer(r'(```.*?```|`[^`]*`)', text, flags=re.DOTALL):
            # –î–æ –∫–æ–¥–∞
            if m.start() > last_end:
                seg = text[last_end:m.start()]
                segments.append(re.sub(r'([_*[\]()~`>#+\-=|{}.!])', r'\\\1', seg))
            segments.append(m.group(0))
            last_end = m.end()
        if last_end < len(text):
            seg = text[last_end:]
            segments.append(re.sub(r'([_*[\]()~`>#+\-=|{}.!])', r'\\\1', seg))
        fixed = ''.join(segments)
        fixed = re.sub(r'\\+$', '', fixed)  # Telegram –Ω–µ –ª—é–±–∏—Ç –æ–±—Ä–∞—Ç–Ω—ã–µ —Å–ª—ç—à–∏ –≤ –∫–æ–Ω—Ü–µ
        return fixed

    def _final_antiartifacts(self, text: str) -> str:
        # –£–¥–∞–ª—è–µ–º –æ–ø–∞—Å–Ω—ã–µ –Ω–µ–≤–∏–¥–∏–º—ã–µ —Å–∏–º–≤–æ–ª—ã (–∫—Ä–æ–º–µ \n –∏ –±–∞–∑–æ–≤—ã—Ö)
        text = re.sub(r'[^\x09\x0A\x0D\x20-\x7E–∞-—è–ê-–Ø—ë–Åa-zA-Z0-9.,:;!?()\[\]{}<>@#%^&*_+=/\\|\'\"`~$‚Ññ-]', '', text)
        text = re.sub(r'\.{3,}', '‚Ä¶', text)
        text = re.sub(r',,+', ',', text)
        text = re.sub(r' {2,}', ' ', text)
        text = re.sub(r'\[([^\]]+)\]\((javascript|data):[^\)]+\)', r'\1', text, flags=re.I)
        text = re.sub(r'[\u200b-\u200f\u202a-\u202e]', '', text)
        return text.strip()

    def remove_tables(self, text: str) -> str:
        """
        –£–¥–∞–ª—è–µ—Ç markdown –∏ html —Ç–∞–±–ª–∏—Ü—ã.
        """
        text = self.MARKDOWN_TABLE_PATTERN.sub('', text)
        text = self.HTML_TABLE_PATTERN.sub('', text)
        return text

    def remove_thinking_blocks(self, text: str) -> str:
        """
        –£–¥–∞–ª—è–µ—Ç –≤—Å–µ –±–ª–æ–∫–∏ —Ä–∞–∑–º—ã—à–ª–µ–Ω–∏–π <think>...</think> (–∏ –≤–∞—Ä–∏–∞—Ü–∏–∏).
        """
        text = self.THINK_PATTERN.sub('', text)
        # –ò–Ω–æ–≥–¥–∞ —Ä–∞–∑–º—ã—à–ª–µ–Ω–∏—è –º–æ–≥—É—Ç –±—ã—Ç—å –≤—ã–¥–µ–ª–µ–Ω—ã –ø—Å–µ–≤–¥–æ—Ç–µ–≥–∞–º–∏ –∏–ª–∏ markdown ‚Äî –¥–æ–±–∞–≤—å –ø–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
        # –ù–∞–ø—Ä–∏–º–µ—Ä, <—Ä–∞–∑–º—ã—à–ª–µ–Ω–∏–µ>...</—Ä–∞–∑–º—ã—à–ª–µ–Ω–∏–µ>, [think]...[/think], –∏ —Ç.–ø.
        return text

    def clean_html_markdown(self, text: str) -> str:
        """
        –£–±–∏—Ä–∞–µ—Ç html/markdown —Ç–µ–≥–∏, –∫—Ä–æ–º–µ –±–µ–∑–æ–ø–∞—Å–Ω—ã—Ö –¥–ª—è Telegram.
        """
        # –£–¥–∞–ª—è–µ–º –≤—Å–µ html-—Ç–µ–≥–∏ –∫—Ä–æ–º–µ <b>, <i>, <u>, <s>, <code>, <pre>, <a>
        allowed_tags = ['b','i','u','s','code','pre','a']
        text = re.sub(r'<(?!\/?(?:' + '|'.join(allowed_tags) + r')\b)[^>]+>', '', text, flags=re.IGNORECASE)
        # –£–¥–∞–ª—è–µ–º markdown –∑–∞–≥–æ–ª–æ–≤–∫–∏, —Å–ø–∏—Å–∫–∏, –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã —Ä–∞–∑–º–µ—Ç–∫–∏
        text = re.sub(r'^\s*#.*$', '', text, flags=re.MULTILINE)
        text = re.sub(r'^\s*[-*]\s+', '', text, flags=re.MULTILINE)
        # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã–µ –ª–∏–Ω–∏–∏
        text = re.sub(r'^[-=]{3,}$', '', text, flags=re.MULTILINE)
        return text

    def validate_content_quality(self, text: str) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –±–µ—Å—Å–º—ã—Å–ª–µ–Ω–Ω—ã–π, –ø—É—Å—Ç–æ–π –∏–ª–∏ "—Å–ø–∞–º–Ω—ã–π" —Ä–µ–∑—É–ª—å—Ç–∞—Ç.
        """
        if not text or not isinstance(text, str):
            return False
        # –°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ
        if len(text) < 15:
            return False
        # –¢–æ–ª—å–∫–æ —ç–º–æ–¥–∑–∏ –∏–ª–∏ —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã
        if re.fullmatch(r'[\s.,:;!?()\[\]{}<>@#%^&*_+=/\\|\'\"`~$‚Ññ0-9a-zA-Z–∞-—è–ê-–Ø—ë–Å-]*', text):
            return False
        # –ü–æ–≤—Ç–æ—Ä –æ–¥–Ω–æ–≥–æ –∏ —Ç–æ–≥–æ –∂–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è/—Å–ª–æ–≤–∞
        lines = [l.strip() for l in text.split('\n') if l.strip()]
        if len(set(lines)) <= 2 and len(lines) > 1:
            return False
        # –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –æ–¥–∏–Ω–∞–∫–æ–≤—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤ –ø–æ–¥—Ä—è–¥ (—Å–ø–∞–º)
        if re.search(r'(.)\1{10,}', text):
            return False
        return True

    # –î–ª—è —Ç–µ—Å—Ç–æ–≤ –∏ –æ—Ç–ª–∞–¥–∫–∏
    def validate_plain(self, text: str, limit: int = 4096) -> str:
        text = self._basic_cleanup(text)
        text = self._deduplicate_empty_lines(text)
        text = self._remove_forbidden_symbols(text)
        text = text[:limit]
        return text.strip()


# —É—á–∞—Å—Ç–æ–∫ –∫–æ–¥–∞ —Ñ–∞–π–ª–∞ lm_client.py

import logging
import requests
from typing import Dict, Any, List, Optional

class LMStudioClient:
    """
    –ö–ª–∏–µ–Ω—Ç –¥–ª—è –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å LM Studio (–ª–æ–∫–∞–ª—å–Ω–∞—è LLM).
    –ö–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ—Ç –ª–∏–º–∏—Ç payload (prompt + history + system_message) –¥–ª—è LM Studio.
    –ù–µ –∑–∞–Ω–∏–º–∞–µ—Ç—Å—è Telegram-–≤–∞–ª–∏–¥–∏—Ä–æ–≤–∞–Ω–∏–µ–º –∏ –Ω–µ —Ä–µ–∂–µ—Ç –ø–æ –ª–∏–º–∏—Ç–∞–º Telegram ‚Äî —Ç–æ–ª—å–∫–æ –ª–∏–º–∏—Ç —Å–∞–º–æ–π LLM!
    """

    LM_MAX_TOTAL_CHARS = 20000  # –õ–∏–º–∏—Ç –¥–ª—è LM Studio (–ø–æ–¥ —Å–≤–æ—é –º–æ–¥–µ–ª—å!)

    def __init__(self, base_url: str, model: str, config: Dict[str, Any]):
        self.base_url = base_url.rstrip("/")
        self.model = model
        self.max_tokens = config.get("max_tokens", 4096)
        self.temperature = config.get("temperature", 0.7)
        self.timeout = config.get("timeout", 60)
        self.history_limit = config.get("history_limit", 3)
        self.system_message = config.get("system_message", None)
        self.top_p = config.get("top_p", None)
        self.top_k = config.get("top_k", None)
        self.logger = logging.getLogger("LMStudioClient")
        self.history: List[Dict[str, str]] = []
        self._validate_config()
        self._check_health_on_init()

    def _validate_config(self):
        assert isinstance(self.max_tokens, int) and self.max_tokens > 0, "max_tokens must be positive integer"
        assert isinstance(self.LM_MAX_TOTAL_CHARS, int) and self.LM_MAX_TOTAL_CHARS > 1000, "LM_MAX_TOTAL_CHARS must be > 1000"
        assert isinstance(self.temperature, (float, int)), "temperature must be float"
        if self.top_p is not None:
            assert 0.0 <= self.top_p <= 1.0, "top_p must be in [0,1]"
        if self.top_k is not None:
            assert isinstance(self.top_k, int) and self.top_k >= 0, "top_k must be non-negative int"

    def _check_health_on_init(self):
        try:
            status = self.health_check()
            if status.get("status") != "ok":
                raise RuntimeError(f"LM Studio health check failed: {status}")
            self.logger.info(f"LMStudioClient connected to model '{self.model}'. Health OK.")
        except Exception as e:
            self.logger.error(f"LM Studio health check failed: {e}")
            raise

    def health_check(self) -> dict:
        try:
            resp = requests.get(f"{self.base_url}/health", timeout=10)
            resp.raise_for_status()
            return resp.json()
        except Exception as e:
            self.logger.error(f"Health check failed: {e}")
            return {"status": "unreachable"}

    def clear_conversation_history(self):
        self.history = []
        self.logger.debug("LMStudioClient: conversation history cleared.")

    def add_to_history(self, user_message: str, bot_message: str):
        if user_message and isinstance(user_message, str) and user_message.strip():
            self.history.append({"role": "user", "content": user_message})
        if bot_message and isinstance(bot_message, str) and bot_message.strip():
            self.history.append({"role": "assistant", "content": bot_message})
        # Trim to the last N exchanges
        if self.history_limit > 0 and len(self.history) > self.history_limit * 2:
            self.history = self.history[-self.history_limit * 2:]

    def _clean_history(self) -> List[Dict[str, str]]:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–æ–ª—å–∫–æ –≤–∞–ª–∏–¥–Ω—ã–µ –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è, –ø—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É.
        """
        clean = []
        for m in self.history[-self.history_limit * 2:]:
            if (
                isinstance(m, dict)
                and m.get("role") in {"user", "assistant", "system"}
                and isinstance(m.get("content"), str)
                and m["content"].strip()
                and "nan" not in m["content"]
            ):
                clean.append(m)
            else:
                self.logger.warning(f"Skipping invalid message in LLM history: {m}")
        return clean

    def _truncate_context_for_llm(self, prompt_template: str, topic: str, context: str, media_file: Optional[str]) -> str:
        """
        –ü–æ–¥–±–∏—Ä–∞–µ—Ç –¥–ª–∏–Ω—É context —Ç–∞–∫, —á—Ç–æ–±—ã prompt + history + system_message –≤–ª–µ–∑–ª–∏ –≤ LM Studio –ª–∏–º–∏—Ç.
        –û–±—Ä–µ–∑–∞–µ—Ç context, –µ—Å–ª–∏ –Ω–∞–¥–æ.
        """
        # –ü–æ–¥—Å—Ç–∞–≤–ª—è–µ–º –≤—Å–µ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä—ã –∫—Ä–æ–º–µ {CONTEXT}
        replacements = {
            "{TOPIC}": topic.strip(),
            "{CONTEXT}": "CONTEXT_PLACEHOLDER",
            "{UPLOADFILE}": media_file.strip() if media_file else "",
        }
        prompt_wo_context = prompt_template
        for key, value in replacements.items():
            prompt_wo_context = prompt_wo_context.replace(key, value)
        prompt_wo_context_len = len(prompt_wo_context.replace("CONTEXT_PLACEHOLDER", ""))

        # –°—á–∏—Ç–∞–µ–º —Ä–∞–∑–º–µ—Ä –∏—Å—Ç–æ—Ä–∏–∏ –∏ system_message
        messages = []
        if self.system_message:
            messages.append({"role": "system", "content": self.system_message})
        messages.extend(self._clean_history())
        static_chars = sum(len(m["content"]) for m in messages) + prompt_wo_context_len
        available = self.LM_MAX_TOTAL_CHARS - static_chars
        if available <= 0:
            self.logger.warning(f"No room for context: static_chars={static_chars} > limit={self.LM_MAX_TOTAL_CHARS}")
            return ""
        context = context.strip()
        if len(context) > available:
            self.logger.warning(f"Context too long for LLM ({len(context)} > {available}), truncating context")
            context = context[:available]
        return context

    def _build_messages(self, prompt_template: str, topic: str, context: str, media_file: Optional[str]) -> List[Dict[str, str]]:
        """
        –°–æ–±–∏—Ä–∞–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è LLM API, –ø—Ä–∏–º–µ–Ω—è–µ—Ç –ª–∏–º–∏—Ç—ã.
        """
        context = self._truncate_context_for_llm(prompt_template, topic, context, media_file)
        replacements = {
            "{TOPIC}": topic.strip(),
            "{CONTEXT}": context,
            "{UPLOADFILE}": media_file.strip() if media_file else "",
        }
        prompt = prompt_template
        for key, value in replacements.items():
            prompt = prompt.replace(key, value)
        prompt = prompt.replace("nan", "").strip()
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Å—Ç–æ—Ä–∏—é
        messages = []
        if self.system_message:
            messages.append({"role": "system", "content": self.system_message})
        messages.extend(self._clean_history())
        messages.append({"role": "user", "content": prompt})
        # –ï—â—ë —Ä–∞–∑ –ø—Ä–æ–≤–µ—Ä—è–µ–º –ª–∏–º–∏—Ç
        total_chars = sum(len(m["content"]) for m in messages)
        if total_chars > self.LM_MAX_TOTAL_CHARS:
            self.logger.warning(f"Total LLM payload too long ({total_chars} > {self.LM_MAX_TOTAL_CHARS}), trimming prompt/history")
            # –û–±—Ä–µ–∑–∞–µ–º prompt
            excess = total_chars - self.LM_MAX_TOTAL_CHARS
            if len(messages[-1]["content"]) > excess:
                messages[-1]["content"] = messages[-1]["content"][:len(messages[-1]["content"]) - excess]
            else:
                # –£–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ä—ã–µ –∏—Å—Ç–æ—Ä–∏–∏
                while total_chars > self.LM_MAX_TOTAL_CHARS and len(messages) > 2:
                    removed = messages.pop(1)  # –ø–æ—Å–ª–µ system_message
                    self.logger.warning(f"Removed old history message to fit LM payload: {removed}")
                    total_chars = sum(len(m["content"]) for m in messages)
                if total_chars > self.LM_MAX_TOTAL_CHARS:
                    last = messages[-1]
                    last["content"] = last["content"][:max(0, len(last["content"]) - (total_chars - self.LM_MAX_TOTAL_CHARS))]
        return messages

    def generate_content(
        self,
        prompt_template: str,
        topic: str,
        context: str,
        media_file: Optional[str] = None,
        max_tokens: Optional[int] = None
    ) -> str:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç —Å –ø–æ–º–æ—â—å—é LM Studio, –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ—Ç –≤–µ—Å—å payload –¥–æ LM_MAX_TOTAL_CHARS.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä–æ–∫—É –∏–ª–∏ –±—Ä–æ—Å–∞–µ—Ç ValueError.
        """
        max_tokens = max_tokens or self.max_tokens
        messages = self._build_messages(prompt_template, topic, context, media_file)
        chat_url = f"{self.base_url}/v1/chat/completions"
        payload_chat = {
            "model": self.model,
            "messages": messages,
            "temperature": self.temperature,
            "max_tokens": max_tokens
        }
        if self.top_p is not None:
            payload_chat["top_p"] = self.top_p
        if self.top_k is not None:
            payload_chat["top_k"] = self.top_k

        self.logger.debug(f"LMStudioClient: Sending chat payload to {chat_url}: {str(payload_chat)[:800]}")

        try:
            response = requests.post(chat_url, json=payload_chat, timeout=self.timeout)
            self.logger.debug(f"LMStudioClient: raw response: {response.text[:1000]}")
            response.raise_for_status()
            try:
                result = response.json()
            except Exception as e:
                self.logger.error("Failed to decode LM Studio response as JSON", exc_info=True)
                result = {}
            text = result.get("choices", [{}])[0].get("message", {}).get("content", "")

            # Fallback –µ—Å–ª–∏ –ø—É—Å—Ç–æ –∏–ª–∏ endpoint –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∞–Ω
            if not text:
                self.logger.warning("Empty chat response, fallback to completions endpoint.")
                comp_url = f"{self.base_url}/v1/completions"
                payload = {
                    "model": self.model,
                    "prompt": messages[-1]['content'],
                    "max_tokens": max_tokens,
                    "temperature": self.temperature,
                    "stream": False
                }
                if self.top_p is not None:
                    payload["top_p"] = self.top_p
                if self.top_k is not None:
                    payload["top_k"] = self.top_k
                comp_resp = requests.post(comp_url, json=payload, timeout=self.timeout)
                comp_resp.raise_for_status()
                try:
                    comp_result = comp_resp.json()
                except Exception as e:
                    self.logger.error("Failed to decode completions response as JSON", exc_info=True)
                    comp_result = {}
                text = comp_result.get("choices", [{}])[0].get("text", "")

            if text and text.strip():
                self.add_to_history(messages[-1]['content'], text)
            else:
                self.logger.warning("LM Studio returned empty text from both endpoints.")
            if not isinstance(text, str):
                raise ValueError("LM Studio returned non-string result.")
            return text.strip()
        except Exception as e:
            self.logger.error("Content generation failed on both endpoints", exc_info=True)
            self.clear_conversation_history()
            raise ValueError(f"LM Studio content generation failed: {e}")

    def generate_with_retry(
        self,
        prompt_template: str,
        topic: str,
        context: str,
        media_file: Optional[str] = None,
        max_retries: int = 3
    ) -> str:
        """
        –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–≤—Ç–æ—Ä –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö, —Å —É—á—ë—Ç–æ–º –ª–∏–º–∏—Ç–∞ –Ω–∞ payload.
        –ü—Ä–∏ –æ—à–∏–±–∫–µ 400 ‚Äî —É–º–µ–Ω—å—à–∞–µ—Ç context –∏ –æ—á–∏—â–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—é.
        """
        last_err = None
        original_context = context
        for attempt in range(1, max_retries + 1):
            try:
                self.logger.debug(f"LMStudioClient: generation attempt {attempt}/{max_retries}")
                text = self.generate_content(prompt_template, topic, context, media_file)
                if text and text.strip():
                    return text
                self.logger.warning(f"LM Studio generation returned empty text (attempt {attempt})")
            except Exception as e:
                last_err = e
                msg = str(e)
                self.logger.warning(f"LMStudioClient: error on attempt {attempt}: {msg}")
                # –ï—Å–ª–∏ payload —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π ‚Äî —Å–æ–∫—Ä–∞—â–∞–µ–º context
                if "413" in msg or "400" in msg or "payload" in msg:
                    context = context[:max(100, len(context) // 2)]
                    self.logger.warning("Reducing context and retrying...")
                # –ü—Ä–∏ –ø–æ–≤—Ç–æ—Ä—è—é—â–µ–π—Å—è –æ—à–∏–±–∫–µ ‚Äî —Å–±—Ä–∞—Å—ã–≤–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é
                if attempt == max_retries or (self.history_limit and len(self.history) > self.history_limit * 4):
                    self.logger.warning("Clearing conversation history due to repeated failures.")
                    self.clear_conversation_history()
        # –ü–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞ ‚Äî —Å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º context –∏ —á–∏—Å—Ç–æ–π –∏—Å—Ç–æ—Ä–∏–µ–π
        try:
            return self.generate_content(prompt_template, topic, original_context[:256], media_file)
        except Exception as e:
            self.logger.error("Final fallback attempt failed", exc_info=True)
            raise ValueError(f"LM Studio did not generate content after {max_retries} attempts: {last_err}")

    def set_generation_parameters(self, temperature: float, top_p: Optional[float] = None, top_k: Optional[int] = None):
        assert 0.0 <= temperature <= 2.0, "temperature must be in [0,2]"
        self.temperature = temperature
        if top_p is not None:
            assert 0.0 <= top_p <= 1.0, "top_p must be in [0,1]"
            self.top_p = top_p
        if top_k is not None:
            assert isinstance(top_k, int) and top_k >= 0, "top_k must be non-negative int"
            self.top_k = top_k
        self.logger.info(f"Set generation parameters: temperature={temperature}, top_p={top_p}, top_k={top_k}")

    def get_generation_stats(self) -> dict:
        return {
            "temperature": self.temperature,
            "max_tokens": self.max_tokens,
            "timeout": self.timeout,
            "history_limit": self.history_limit,
            "system_message": self.system_message,
            "top_p": self.top_p,
            "top_k": self.top_k
        }

# —É—á–∞—Å—Ç–æ–∫ –∫–æ–¥–∞ —Ñ–∞–π–ª–∞ prompt_builder.py

import os
import random
import logging
import re
from pathlib import Path
from typing import List, Dict, Optional, Tuple

class PromptBuilder:
    """
    –°–±–æ—Ä–∫–∞ –ø—Ä–æ–º–ø—Ç–∞ –∏–∑ —à–∞–±–ª–æ–Ω–æ–≤ —Å –∂–µ—Å—Ç–∫–∏–º –∫–æ–Ω—Ç—Ä–æ–ª–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—ã, –ø–æ–¥—Å—Ç–∞–Ω–æ–≤–∫–∏ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–æ–≤,
    –∏ –Ω–∞–¥–µ–∂–Ω—ã–º –≤–æ–∑–≤—Ä–∞—Ç–æ–º –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤—Å–µ–π —Ü–µ–ø–æ—á–∫–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏.
    """

    REQUIRED_PLACEHOLDERS = ["{TOPIC}", "{CONTEXT}"]
    OPTIONAL_PLACEHOLDERS = ["{UPLOADFILE}"]
    PLACEHOLDER_PATTERN = re.compile(r"\{[A-Z_]+\}")

    def __init__(self, prompt_folders: List[str]):
        self.prompt_folders = [Path(folder) for folder in prompt_folders]
        self.logger = logging.getLogger("PromptBuilder")
        self.templates: Dict[str, List[str]] = {}
        self.error_history: List[Dict] = []
        self._last_prompt_template: Optional[str] = None
        self.load_prompt_templates()

    def load_prompt_templates(self) -> None:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —à–∞–±–ª–æ–Ω—ã –∏–∑ –≤—Å–µ—Ö —É–∫–∞–∑–∞–Ω–Ω—ã—Ö –ø–∞–ø–æ–∫, —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø—É—Ç–∏."""
        for folder in self.prompt_folders:
            if not folder.exists():
                self.logger.warning(f"Prompt folder does not exist: {folder}")
                self.templates[str(folder)] = []
                continue
            self.templates[str(folder)] = self._scan_prompt_folder(folder)
            self.logger.info(f"Loaded {len(self.templates[str(folder)])} templates from {folder}")

    def _scan_prompt_folder(self, folder_path: Path) -> List[str]:
        return [str(p) for p in folder_path.glob("*.txt")]

    def _select_random_templates(self) -> List[str]:
        """–ò–∑ –∫–∞–∂–¥–æ–π –ø–∞–ø–∫–∏ –≤—ã–±–∏—Ä–∞–µ—Ç —Å–ª—É—á–∞–π–Ω—ã–π —à–∞–±–ª–æ–Ω. –ï—Å–ª–∏ –Ω–µ—Ç —Ñ–∞–π–ª–æ–≤ ‚Äî None."""
        selected = []
        for folder in self.prompt_folders:
            templates = self.templates.get(str(folder), [])
            selected.append(random.choice(templates) if templates else None)
        return selected

    def _read_template_file(self, file_path: Optional[str]) -> str:
        if not file_path:
            return ""
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                return f.read()
        except Exception as e:
            msg = f"Failed to read prompt file: {file_path}"
            self._log_error(msg, exc=e)
            return ""

    def _validate_prompt_structure(self, template: str) -> None:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –≤—Å–µ—Ö –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–æ–≤. –ö–∏–¥–∞–µ—Ç –æ—à–∏–±–∫—É –µ—Å–ª–∏ –Ω–µ–≤–∞–ª–∏–¥–Ω–æ."""
        missing = [ph for ph in self.REQUIRED_PLACEHOLDERS if ph not in template]
        if missing:
            msg = f"Prompt missing required placeholders: {missing}"
            self._log_error(msg)
            self.logger.error(msg)
            raise ValueError(msg)
        # –õ–æ–≥–∏—Ä—É–µ–º –¥—É–±–ª–∏, –Ω–µ –≤–∞–ª–∏–º —Ä–∞–±–æ—Ç—É
        for ph in self.REQUIRED_PLACEHOLDERS + self.OPTIONAL_PLACEHOLDERS:
            if ph * 2 in template:
                self.logger.warning(f"Prompt contains duplicated placeholder: {ph}{ph}")
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–µ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä—ã
        all_placeholders = set(self.PLACEHOLDER_PATTERN.findall(template))
        supported = set(self.REQUIRED_PLACEHOLDERS + self.OPTIONAL_PLACEHOLDERS)
        unsupported = [ph for ph in all_placeholders if ph not in supported]
        if unsupported:
            self.logger.warning(f"Prompt contains unsupported placeholders: {unsupported}")

    def _find_unresolved_placeholders(self, text: str) -> List[str]:
        return list(set(self.PLACEHOLDER_PATTERN.findall(text)))

    def _compact_whitespace(self, text: str) -> str:
        return re.sub(r"\n{3,}", "\n\n", text)

    def _replace_placeholders(self, template: str, replacements: Dict[str, str]) -> str:
        for key, value in replacements.items():
            template = template.replace(key, value)
        return template

    def _has_uploadfile_placeholder(self, template: str) -> bool:
        return "{UPLOADFILE}" in template

    def build_prompt(
        self,
        topic: str,
        context: str,
        media_file: Optional[str] = None
    ) -> Tuple[str, bool, str]:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
            - prompt (str): –∏—Ç–æ–≥–æ–≤—ã–π —Ç–µ–∫—Å—Ç –ø—Ä–æ–º–ø—Ç–∞ –±–µ–∑ –Ω–µ—Ä–∞–∑—Ä–µ—à—ë–Ω–Ω—ã—Ö –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–æ–≤
            - has_uploadfile (bool): True, –µ—Å–ª–∏ –≤ —à–∞–±–ª–æ–Ω–µ –±—ã–ª {UPLOADFILE} –∏ –æ–Ω –±—ã–ª –∑–∞–º–µ–Ω—ë–Ω
            - prompt_template (str): –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç —à–∞–±–ª–æ–Ω–∞ (–¥–æ –ø–æ–¥—Å—Ç–∞–Ω–æ–≤–∫–∏)
        """
        # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        if not topic or not isinstance(topic, str):
            msg = "Topic for prompt_builder is empty or not a string."
            self._log_error(msg, context={"topic": topic})
            self.logger.error(msg)
            raise ValueError(msg)
        if not context or not isinstance(context, str):
            msg = "Context for prompt_builder is empty or not a string."
            self._log_error(msg, context={"context": context})
            self.logger.error(msg)
            raise ValueError(msg)

        # 2. –í—ã–±–æ—Ä —à–∞–±–ª–æ–Ω–æ–≤
        template_paths = self._select_random_templates()
        template_texts = [self._read_template_file(path) for path in template_paths if path]
        # –ï—Å–ª–∏ –≤—Å–µ —à–∞–±–ª–æ–Ω—ã –ø—É—Å—Ç—ã ‚Äî –¥–µ—Ñ–æ–ª—Ç
        if not any(template_texts):
            prompt_template = self._default_template()
            self.logger.warning("No prompt templates found, using default.")
        else:
            prompt_template = "\n\n".join(filter(None, template_texts)).strip()

        self._last_prompt_template = prompt_template

        # 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –î–û –ø–æ–¥—Å—Ç–∞–Ω–æ–≤–∫–∏
        self._validate_prompt_structure(prompt_template)

        # 4. –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –Ω—É–∂–µ–Ω –ª–∏ uploadfile
        has_uploadfile = self._has_uploadfile_placeholder(prompt_template)
        replacements = {
            "{TOPIC}": topic.strip(),
            "{CONTEXT}": context.strip(),
            "{UPLOADFILE}": media_file.strip() if (has_uploadfile and media_file) else "",
        }
        prompt = self._replace_placeholders(prompt_template, replacements)

        # 5. –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ—Å–ª–µ –ø–æ–¥—Å—Ç–∞–Ω–æ–≤–∫–∏: –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å –ª–∏ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–æ–≤
        unresolved = self._find_unresolved_placeholders(prompt)
        critical_unresolved = [
            ph for ph in unresolved if
            ph in self.REQUIRED_PLACEHOLDERS or
            (ph == "{UPLOADFILE}" and has_uploadfile)
        ]
        if critical_unresolved:
            msg = f"Prompt contains unresolved placeholders after replacement: {critical_unresolved}"
            self._log_error(msg, context={"prompt": prompt, "replacements": replacements})
            self.logger.error(msg)
            raise ValueError(msg)

        # 6. –û—á–∏—Å—Ç–∫–∞ whitespace
        prompt = self._compact_whitespace(prompt)

        self.logger.debug(
            f"PromptBuilder: topic='{topic[:100]}', context_len={len(context)}, media_file='{media_file}', has_uploadfile={has_uploadfile}")
        self.logger.debug(f"PromptBuilder: template_paths={template_paths}")
        self.logger.debug(f"PromptBuilder: prompt after replacement (truncated): {prompt[:1000]}")

        return prompt, has_uploadfile, prompt_template

    def _log_error(self, msg: str, context: Optional[dict] = None, exc: Exception = None):
        entry = {
            "message": msg,
            "context": context,
            "exception": repr(exc) if exc else None
        }
        self.error_history.append(entry)
        if len(self.error_history) > 100:
            self.error_history = self.error_history[-100:]

    def get_error_history(self) -> List[Dict]:
        return self.error_history.copy()

    def check_placeholder_presence(self, template: str) -> Dict[str, bool]:
        all_ph = self.REQUIRED_PLACEHOLDERS + self.OPTIONAL_PLACEHOLDERS
        return {ph: (ph in template) for ph in all_ph}

    def get_template_stats(self) -> Dict[str, int]:
        return {folder: len(templates) for folder, templates in self.templates.items()}

    def reload_templates(self) -> None:
        self.logger.info("Reloading prompt templates...")
        self.load_prompt_templates()

    def test_template_combination(self, topic: str, context: str) -> Tuple[str, bool, str]:
        return self.build_prompt(topic, context, media_file="media/sample.jpg")

    def _default_template(self) -> str:
        return (
            "–¢—ã –æ–ø—ã—Ç–Ω—ã–π –º–µ—Ö–∞–Ω–∏–∫ –≥—Ä—É–∑–æ–≤–æ–π —Ç–µ—Ö–Ω–∏–∫–∏ —Å 15-–ª–µ—Ç–Ω–∏–º —Å—Ç–∞–∂–µ–º —Ä–∞–±–æ—Ç—ã.\n"
            "–†–∞–±–æ—Ç–∞–ª –≤ –∫—Ä—É–ø–Ω—ã—Ö –∞–≤—Ç–æ–ø–∞—Ä–∫–∞—Ö, —Ä–µ–º–æ–Ω—Ç–∏—Ä–æ–≤–∞–ª –∫—Ä–∞–Ω—ã, —Ñ—É—Ä–≥–æ–Ω—ã, –±–æ—Ä—Ç–æ–≤—ã–µ –º–∞—à–∏–Ω—ã. "
            "–ó–Ω–∞–µ—à—å –≤—Å–µ –ø–æ–¥–≤–æ–¥–Ω—ã–µ –∫–∞–º–Ω–∏ —ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏–∏. –ì–æ–≤–æ—Ä–∏—à—å –ø—Ä–æ—Å—Ç—ã–º —è–∑—ã–∫–æ–º, –ø—Ä–∏–≤–æ–¥–∏—à—å –ø—Ä–∏–º–µ—Ä—ã –∏–∑ –ø—Ä–∞–∫—Ç–∏–∫–∏.\n\n"
            "–¢–µ–º–∞: {TOPIC}\n\n"
            "–ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞: {CONTEXT}\n"
            "{UPLOADFILE}"
        )

    @property
    def last_prompt_template(self) -> Optional[str]:
        return self._last_prompt_template

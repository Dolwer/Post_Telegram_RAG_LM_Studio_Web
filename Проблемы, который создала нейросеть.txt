# Список основных проблем и ошибок

1. Передача кортежа вместо строки  
   — Методы вроде build_prompt возвращали кортеж (prompt, has_uploadfile, ...), а вызывающий код ожидал строку и вызывал .strip() на кортеже, что приводило к AttributeError: 'tuple' object has no attribute 'strip'.

2. Неверная сигнатура вызова LMStudioClient  
   — После доработки LMStudioClient требовал параметры (prompt_template, topic, context, media_file, ...), а код продолжал передавать только prompt, что приводило к ошибке missing 2 required positional arguments.

3. Ошибка 400 (Bad Request) от LM Studio/OpenAI API  
   — Превышение лимита длины всего payload (prompt+history+system_message), неучёт общего лимита (обычно 16–20 тыс. символов).  
   — В payload попадал мусор: "nan", None, пустые строки, слишком длинные сообщения, неверная структура messages.

4. Обрезка контекста в main.py вместо LMStudioClient  
   — Контекст обрезался «на глаз» по лимиту Telegram, а не по лимиту LM Studio, что не решало проблему 400 ошибки.

5. Неочищенные или невалидные данные  
   — В истории и контексте встречались "nan", None, артефакты, которые не фильтровались перед отправкой.

6. Отсутствие корректного возврата шаблона prompt из PromptBuilder  
   — Не возвращался prompt_template с плейсхолдерами, что мешало корректно собирать payload для LM Studio.

7. Дублирование лимитов на разных уровнях  
   — Запутанность между лимитами Telegram (4096/1024) и лимитом LM Studio (16–20k), что приводило к неверному управлению длиной сообщений.

8. Невнятная или недостаточная обработка ошибок и логирование  
   — Ошибки могли затираться, не логировались причины, не было детального трейсинга проблем.

9. Проблемы с архитектурной целостностью  
   — Не было единого места, где гарантируется корректность и длина payload для LM Studio.

10. Отсутствие валидации и чистки истории сообщений  
    — Старые, слишком длинные или невалидные сообщения не удалялись из истории, что приводило к переполнению payload.

11. Неправильная работа с media_file и has_uploadfile  
    — Логика передачи медиафайлов и их влияния на лимиты могла быть нарушена, приводя к несогласованности между caption/text.

12. Слабый контроль над форматами и структурой messages  
    — Возможна отправка некорректных messages (role, пустой content), что ломает API LM Studio.

13. Отсутствие централизованного ограничения на размер всего prompt/history  
    — Payload мог разрастаться из-за отсутствия единого контроля, даже если отдельные части были в лимите.

14. Неполное тестирование на граничных случаях  
    — Система могла падать или выдавать ошибки на больших темах, длинных историях или при нестандартных данных.

15. Проблемы с возвратом корректной информации из PromptBuilder  
    — Не возвращались все нужные атрибуты (prompt, has_uploadfile, prompt_template), что мешало правильной работе.

16. Проблемы с повторной генерацией и очисткой истории  
    — История диалога могла не сбрасываться после серии неудачных попыток, что усугубляло ошибку 400.

17. Недостаточный контроль над структурой JSON для LM Studio  
    — Возможна отправка некорректного JSON (например, массивов неправильной структуры), что приводит к ошибкам декодирования.

18. Неочевидность и неудобство возврата ошибок в мониторинг  
    — Ошибки не всегда попадали в мониторинг и отчёты, что затрудняло отладку.

19. Неочевидная работа с лимитами токенов vs символов  
    — Не всегда учитывалось различие между лимитами в символах и токенах для разных движков.

20. Мусорные или дублирующиеся сообщения в истории  
    — Дублирование, попадание мусора, невалидных записей из-за недостаточной фильтрации.